# ğŸ› ï¸ EndÃ¼striyel ArÄ±za KodlarÄ± EÅŸleÅŸtirme Projesi

Bu projede, endÃ¼striyel sistemlerde ortaya Ã§Ä±kan arÄ±za aÃ§Ä±klamalarÄ±nÄ± doÄŸal dil iÅŸleme (NLP) yÃ¶ntemleri kullanarak teknik hata kodlarÄ± ile eÅŸleÅŸtirmektir. Bu sayede teknik personelin sistemde oluÅŸan arÄ±zalarÄ± daha hÄ±zlÄ± ve doÄŸru bir ÅŸekilde sÄ±nÄ±flandÄ±rmasÄ± saÄŸlanÄ±r.

---

## 1. Hafta â€” Veri HazÄ±rlama ve Ã–niÅŸleme
1.1. Veri Toplama

ilk olarak endÃ¼striyel otomotiv ve makineleri Ã§ekilmiÅŸtir daha sonra bu verilerin hata kodu aÃ§Ä±klamasÄ±nÄ±n olduÄŸu sÃ¼tunlarÄ±na ayrÄ±lmÄ±ÅŸtÄ±r.
AyÄ±rÄ±lan aÃ§Ä±klama sÃ¼tunlarÄ±nÄ± birleÅŸtirerek yeni bir csv (birlesik_aciklamalar.csv) dosyasÄ±na kaydedilmiÅŸtir.
yeni csv dosyasÄ± Ã¼zerinde aÅŸaÄŸÄ±daki iÅŸlemleri uyguladÄ±m.
-Bu Ã§alÄ±ÅŸmam ise `Endustriyel_Ariza_Kodlari_Eslestirme.ipynb` adlÄ± kaynak dosyasÄ±nda bulunmaktadÄ±r

1.2. Veri Ã–n Ä°ÅŸleme
AÃ§Ä±klama verileri Ã¼zerinde gerÃ§ekleÅŸtirilen temel iÅŸlemler:

-  KÃ¼Ã§Ã¼k harfe Ã§evirme  
-  Noktalama iÅŸaretlerinin kaldÄ±rÄ±lmasÄ±  
-  Ä°ngilizce stopword (gereksiz kelimeler) temizliÄŸi  
-  Tokenizasyon (metni kelimelere ayÄ±rma)  
-  Lemmatizasyon ( Kelimeler kÃ¶klerine indirgenerek farklÄ± Ã§ekimler aynÄ± forma getirilmiÅŸtir.) 
-  Stemming: Kelimenin kÃ¶kÃ¼nÃ¼ bulmak iÃ§in yapÄ±lmÄ±ÅŸtÄ±r

---

## ğŸ” Proje Ã–zeti

CSV dosyasÄ±ndan alÄ±nan aÃ§Ä±klamalar ÅŸu adÄ±mlardan geÃ§irilmiÅŸtir:

- Verinin `pandas` ile yÃ¼klenmesi ve genel incelemesi
- Eksik verilerin kontrolÃ¼
- CÃ¼mle ve kelime seviyesinde ayrÄ±ÅŸtÄ±rma (`tokenization`)
- Ä°ngilizce stopwords (nltk) ile filtreleme
- Lemmatizasyon ve stemleme iÅŸlemleriyle kelimelerin kÃ¶k formlarÄ±nÄ±n Ã§Ä±karÄ±lmasÄ±
- CÃ¼mle listesi oluÅŸturularak yapÄ±sal analiz yapÄ±lmasÄ±
- Veri Ã¶n iÅŸleme adÄ±mlarÄ±, nltk python, pandas ve re kÃ¼tÃ¼phaneleri kullanÄ±larak Python'da uygulanmÄ±ÅŸtÄ±r.

---

## ğŸ“Š Zipf YasasÄ± Analizi

Veri setindeki kelimelerin frekans daÄŸÄ±lÄ±mÄ± analiz edilerek log-log grafiÄŸi Ã§izilmiÅŸtir. SonuÃ§lar Zipf yasasÄ±na uygunluk gÃ¶stermektedir. 
> ğŸ” `Endustriyel_Ariza_Kodlari_Eslestirme.ipynb` dosyasÄ±nda ilgili analizler ve grafikler yer almaktadÄ±r.

---

## ğŸ› ï¸ KullanÄ±lan Teknolojiler ve KÃ¼tÃ¼phaneler

- Python 3.x
- Jupyter Notebook
- NLTK, pandas, numpy, gensim, scikit-learn

---

## 2. Hafta: TF-IDF VektÃ¶rleÅŸtirme ve Word2Vec Modelleri 

### 2.1. TF-IDF VektÃ¶rleÅŸtirme
TF-IDF yÃ¶ntemiyle metinler vektÃ¶rleÅŸtirilmiÅŸ ve giriÅŸ metniyle cosine similarity skorlarÄ± hesaplanmÄ±ÅŸtÄ±r. 
Her veri tÃ¼rÃ¼ iÃ§in ilk 5 benzer metin ve skorlarÄ± listelenmiÅŸtir.

### 2.2. Cosine Similarity (KosinÃ¼s BenzerliÄŸi) KarÅŸÄ±laÅŸtÄ±rmasÄ±
TÃ¼m modellerin giriÅŸ metniyle olan ortalama ve en yÃ¼ksek cosine similarity skorlarÄ± hesaplanmÄ±ÅŸ ve tablo halinde karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r.

> ğŸ“Œ DetaylÄ± analizler: `Endustriyel_Ariza_Kodlari_Eslestirme.ipynb` iÃ§inde

### 2.3. Jaccard Benzerlik Matrisi
TF-IDF ve Word2Vec modellerinin her birinin ilk 5 benzer metin seÃ§imi alÄ±nÄ±p, bu seÃ§imler arasÄ±nda Jaccard benzerlik skoru hesaplanarak 18x18'lik bir skor matrisi oluÅŸturulmuÅŸtur.

> ğŸ“Œ DetaylÄ± analizler: `Endustriyel_Ariza_Kodlari_Eslestirme.ipynb` iÃ§inde

### 2.4. Word2Vec Model EÄŸitimi ve Ä°nceleme
16 farklÄ± parametre kombinasyonuyla Word2Vec modeli eÄŸitilmiÅŸtir (CBOW / SkipGram, window=2/4, dim=100/300). GiriÅŸ metnine benzerlikler cosine similarity ile deÄŸerlendirilmiÅŸtir.

---

## ğŸ“Œ SonuÃ§lar ve DeÄŸerlendirme

- En yÃ¼ksek ortalama skor: `word2vec_lemmatized_skipgram_win4_dim300`
- En anlamlÄ± sonuÃ§larÄ± sunanlar: `tfidf_lemmatized` ve `skipgram_win4_dim300`
- SkipGram modelleri CBOWâ€™a gÃ¶re, dim=300 modelleri dim=100â€™e gÃ¶re daha baÅŸarÄ±lÄ± olmuÅŸtur.
- TF-IDF yÃ¼zeysel benzerlik sunarken, Word2Vec anlamsal yakÄ±nlÄ±k saÄŸlamÄ±ÅŸtÄ±r.
- Jaccard skorlarÄ± TF-IDF modelleri arasÄ±nda yÃ¼ksek, Word2Vec modelleri arasÄ±nda ise Ã§eÅŸitlilik gÃ¶stermektedir.

---

## ğŸ“¥ NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r?
1. Ã‡alÄ±ÅŸmayÄ± bilgisayarÄ±nÄ±za indirip, arÅŸivden klasÃ¶re Ã§Ä±karÄ±p 'notebooks/Endustriyel_Ariza_Kodlari_Eslestirme.ipynb` dosyasÄ±nÄ± jupyter notebok da aÃ§Ä±nÄ±z ve tÃ¼m hÃ¼creleri sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±n, sonuÃ§larÄ± listelenecektir.
2. Kendi veri setlerinizin analizini yapmak isterseniz sonraki adÄ±mlarÄ± takip edin.
3. `notebooks/`, `models/` klasÃ¶rÃ¼ ve `data/` klasÃ¶rÃ¼ hazÄ±r olmalÄ±dÄ±r.
4. Veri setlerinizi 'data' klasÃ¶rÃ¼ iÃ§erisine atÄ±n, `Endustriyel_Ariza_Kodlari_Eslestirme.ipynb` dosyasÄ±nda veri seti yÃ¼kleme kÄ±smÄ±nda, veri setlerinizin isimlerini doÄŸru ÅŸekilde yazÄ±n ve birleÅŸtirilecek sÃ¼tun isimlerini doÄŸru ÅŸekilde belirtin.
5. HÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n.
6. Ã‡Ä±ktÄ±lar ve karÅŸÄ±laÅŸtÄ±rmalar otomatik olarak Ã¼retilir.