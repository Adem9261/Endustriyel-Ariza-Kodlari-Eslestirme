{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b41c006-4306-4814-a8c2-5f9bb72a63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a077eb9-e355-4ef1-9137-9d51fd263682",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {'model_type': 'cbow', 'window': 2, 'vector_size': 100},\n",
    "    {'model_type': 'skipgram', 'window': 2, 'vector_size': 100},\n",
    "    {'model_type': 'cbow', 'window': 4, 'vector_size': 100},\n",
    "    {'model_type': 'skipgram', 'window': 4, 'vector_size': 100},\n",
    "    {'model_type': 'cbow', 'window': 2, 'vector_size': 300},\n",
    "    {'model_type': 'skipgram', 'window': 2, 'vector_size': 300},\n",
    "    {'model_type': 'cbow', 'window': 4, 'vector_size': 300},\n",
    "    {'model_type': 'skipgram', 'window': 4, 'vector_size': 300}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a116a95-b4db-46fe-a58e-6b573a1581d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../data/lemmatized_sentences.csv\")\n",
    "df2 = pd.read_csv(\"../data/stemmed_sentences.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5836d294-cfb1-4cc5-a58b-2354dd8dec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = [\"0\"]\n",
    "\n",
    "# NaN değerleri ve boş stringleri temizle\n",
    "df1 = df1.dropna()\n",
    "df1 = df1[df1[\"0\"].str.strip() != \"\"]\n",
    "\n",
    "df2.columns = [\"0\"]\n",
    "\n",
    "# NaN değerleri ve boş stringleri temizle\n",
    "df2 = df2.dropna()\n",
    "df2 = df2[df2[\"0\"].str.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65ca9a8c-3383-4f92-b5ab-c0dc578bca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doğru tokenizasyon fonksiyonu\n",
    "def proper_tokenize(text):\n",
    "    # Özel karakterleri kaldır ve küçük harfe çevir\n",
    "    text = re.sub(r'[^a-zA-ZğüşıöçĞÜŞİÖÇ\\s]', '', text.lower())\n",
    "    # NLTK ile tokenize et\n",
    "    tokens = word_tokenize(text)\n",
    "    # Stopwords'leri ve tek karakterli kelimeleri kaldır\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [word for word in tokens if word not in stop_words and len(word) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab688d90-548f-4d38-bc56-99eabfa8cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doğru tokenizasyon uygula\n",
    "df1['tokens'] = df1['0'].apply(proper_tokenize)\n",
    "df2['tokens'] = df2['0'].apply(proper_tokenize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ecdecc-b454-4121-b0df-7cba2ae1cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token listelerini oluştur\n",
    "tokenized_corpus_lemmatized = df1['tokens'].tolist()\n",
    "tokenized_corpus_stemmed = df2['tokens'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab5ae91-43c8-4121-af8e-facc162e915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_save_model(corpus, param, model_prefix):\n",
    "    model_type = param['model_type']\n",
    "    vector_size = param['vector_size']\n",
    "    window = param['window']\n",
    "    \n",
    "    # CBOW (sg=0) veya Skip-gram (sg=1)\n",
    "    sg = 0 if model_type == 'cbow' else 1\n",
    "\n",
    "    model = Word2Vec(\n",
    "        sentences=corpus,\n",
    "        vector_size=vector_size,\n",
    "        window=window,\n",
    "        min_count=1,\n",
    "        workers=4,\n",
    "        sg=sg\n",
    "    )\n",
    "\n",
    "    model_filename = f\"{model_prefix}_{model_type}_vs{vector_size}_w{window}.model\"\n",
    "    model.save(model_filename)\n",
    "    print(f\"Model saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd3caa7d-ca45-43ca-b967-4ef1cb0ce11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as lemmatized_model_cbow_vs100_w2.model\n",
      "Model saved as lemmatized_model_skipgram_vs100_w2.model\n",
      "Model saved as lemmatized_model_cbow_vs100_w4.model\n",
      "Model saved as lemmatized_model_skipgram_vs100_w4.model\n",
      "Model saved as lemmatized_model_cbow_vs300_w2.model\n",
      "Model saved as lemmatized_model_skipgram_vs300_w2.model\n",
      "Model saved as lemmatized_model_cbow_vs300_w4.model\n",
      "Model saved as lemmatized_model_skipgram_vs300_w4.model\n",
      "Model saved as stemmed_model_cbow_vs100_w2.model\n",
      "Model saved as stemmed_model_skipgram_vs100_w2.model\n",
      "Model saved as stemmed_model_cbow_vs100_w4.model\n",
      "Model saved as stemmed_model_skipgram_vs100_w4.model\n",
      "Model saved as stemmed_model_cbow_vs300_w2.model\n",
      "Model saved as stemmed_model_skipgram_vs300_w2.model\n",
      "Model saved as stemmed_model_cbow_vs300_w4.model\n",
      "Model saved as stemmed_model_skipgram_vs300_w4.model\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize edilmiş corpus ile modelleri eğitme ve kaydetme\n",
    "for param in parameters:\n",
    "    train_and_save_model(tokenized_corpus_lemmatized, param, \"lemmatized_model\")\n",
    "\n",
    "# Stemlenmiş corpus ile modelleri eğitme ve kaydetme\n",
    "for param in parameters:\n",
    "    train_and_save_model(tokenized_corpus_stemmed, param, \"stemmed_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c13ff9e8-2a5f-47cb-9a8a-e340f0323128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model dosyalarını yüklemek\n",
    "model_1 = Word2Vec.load(\"../models/lemmatized_model_cbow_vs100_w2.model\")\n",
    "model_2 = Word2Vec.load(\"../models/lemmatized_model_cbow_vs100_w4.model\")\n",
    "model_3 = Word2Vec.load(\"../models/lemmatized_model_cbow_vs300_w2.model\")\n",
    "model_4 = Word2Vec.load(\"../models/lemmatized_model_cbow_vs300_w4.model\")\n",
    "model_5 = Word2Vec.load(\"../models/lemmatized_model_skipgram_vs100_w2.model\")\n",
    "model_6 = Word2Vec.load(\"../models/lemmatized_model_skipgram_vs100_w4.model\")\n",
    "model_7 = Word2Vec.load(\"../models/lemmatized_model_skipgram_vs300_w2.model\")\n",
    "model_8 = Word2Vec.load(\"../models/lemmatized_model_skipgram_vs300_w4.model\")\n",
    "model_9  = Word2Vec.load(\"../models/stemmed_model_cbow_vs100_w2.model\")\n",
    "model_10 = Word2Vec.load(\"../models/stemmed_model_cbow_vs100_w4.model\")\n",
    "model_11 = Word2Vec.load(\"../models/stemmed_model_cbow_vs300_w2.model\")\n",
    "model_12 = Word2Vec.load(\"../models/stemmed_model_cbow_vs300_w4.model\")\n",
    "model_13 = Word2Vec.load(\"../models/stemmed_model_skipgram_vs100_w2.model\")\n",
    "model_14 = Word2Vec.load(\"../models/stemmed_model_skipgram_vs100_w4.model\")\n",
    "model_15 = Word2Vec.load(\"../models/stemmed_model_skipgram_vs300_w2.model\")\n",
    "model_16 = Word2Vec.load(\"../models/stemmed_model_skipgram_vs300_w4.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b52e78fa-93e2-4686-9744-ec1576fb4c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'error' kelimesi ile en benzer 3 kelimeyi ve skorlarını yazdırmak\n",
    "def print_similar_words(model, model_name):\n",
    "    similarity = model.wv.most_similar(\"error\", topn=3)\n",
    "    print(f\"\\n{model_name} Modeli - 'error' ile En Benzer 3 Kelime:\")\n",
    "    for word, score in similarity:\n",
    "        print(f\"Kelime: {word}, Benzerlik Skoru: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06b834f8-87d8-46c0-baba-48123337eea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatized CBOW Window 2 Dim 100 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: heater, Benzerlik Skoru: 0.27483057975769043\n",
      "Kelime: necessary, Benzerlik Skoru: 0.26221245527267456\n",
      "Kelime: distributor, Benzerlik Skoru: 0.2495647817850113\n",
      "\n",
      "Stemmed Skipgram Window 4 Dim 100 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: heater, Benzerlik Skoru: 0.28107109665870667\n",
      "Kelime: necessary, Benzerlik Skoru: 0.26783761382102966\n",
      "Kelime: alarm, Benzerlik Skoru: 0.25009340047836304\n",
      "\n",
      "Lemmatized Skipgram Window 2 Dim 300 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: heartbeat, Benzerlik Skoru: 0.1780272275209427\n",
      "Kelime: output, Benzerlik Skoru: 0.1670265793800354\n",
      "Kelime: high, Benzerlik Skoru: 0.15835227072238922\n",
      "\n",
      "lemmatized skipgram window 4 dim 100 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: heartbeat, Benzerlik Skoru: 0.17919139564037323\n",
      "Kelime: output, Benzerlik Skoru: 0.17486067116260529\n",
      "Kelime: high, Benzerlik Skoru: 0.17238584160804749\n",
      "\n",
      "lemmatized cbow window 2 dim 300 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: necessary, Benzerlik Skoru: 0.30591607093811035\n",
      "Kelime: circuit, Benzerlik Skoru: 0.29826241731643677\n",
      "Kelime: alarm, Benzerlik Skoru: 0.29708632826805115\n",
      "\n",
      "lemmatizedskipgramwindow 2 dim300 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: circuit, Benzerlik Skoru: 0.4835795760154724\n",
      "Kelime: alarm, Benzerlik Skoru: 0.4179272949695587\n",
      "Kelime: low, Benzerlik Skoru: 0.4012123942375183\n",
      "\n",
      "lemmatized_cbow_window 4_dim300 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: high, Benzerlik Skoru: 0.21965378522872925\n",
      "Kelime: output, Benzerlik Skoru: 0.21853317320346832\n",
      "Kelime: operating, Benzerlik Skoru: 0.1951117217540741\n",
      "\n",
      "lemmatized_skipgram_window4_dim300.model Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: high, Benzerlik Skoru: 0.34696686267852783\n",
      "Kelime: check, Benzerlik Skoru: 0.3291306793689728\n",
      "Kelime: output, Benzerlik Skoru: 0.3279796540737152\n",
      "\n",
      "stemmed_cbow_window2_dim100 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: right, Benzerlik Skoru: 0.3517582416534424\n",
      "Kelime: signal, Benzerlik Skoru: 0.2977377474308014\n",
      "Kelime: undervoltag, Benzerlik Skoru: 0.29721325635910034\n",
      "\n",
      "stemmed_skipgram_window2_dim100 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: right, Benzerlik Skoru: 0.38821083307266235\n",
      "Kelime: signal, Benzerlik Skoru: 0.33034107089042664\n",
      "Kelime: oper, Benzerlik Skoru: 0.3220016360282898\n",
      "\n",
      "stemmed_cbow_window4_dim100 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: pressur, Benzerlik Skoru: 0.2647673487663269\n",
      "Kelime: clear, Benzerlik Skoru: 0.2336159348487854\n",
      "Kelime: failur, Benzerlik Skoru: 0.1841670125722885\n",
      "\n",
      "stemmed_skipgram_window4_dim100 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: pressur, Benzerlik Skoru: 0.3085029721260071\n",
      "Kelime: clear, Benzerlik Skoru: 0.27886852622032166\n",
      "Kelime: check, Benzerlik Skoru: 0.25678911805152893\n",
      "\n",
      "stemmed_cbow_window2_dim300 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: oper, Benzerlik Skoru: 0.4851064085960388\n",
      "Kelime: right, Benzerlik Skoru: 0.4662863612174988\n",
      "Kelime: dc, Benzerlik Skoru: 0.43464094400405884\n",
      "\n",
      "stemmed_skipgram_window2_dim300 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: oper, Benzerlik Skoru: 0.813849925994873\n",
      "Kelime: perform, Benzerlik Skoru: 0.8112281560897827\n",
      "Kelime: system, Benzerlik Skoru: 0.8061442375183105\n",
      "\n",
      "stemmed_cbow_window4_dim300 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: circuit, Benzerlik Skoru: 0.45459413528442383\n",
      "Kelime: pressur, Benzerlik Skoru: 0.43113377690315247\n",
      "Kelime: check, Benzerlik Skoru: 0.4283693730831146\n",
      "\n",
      "stemmed_skipgram_window4_dim300 Modeli - 'error' ile En Benzer 3 Kelime:\n",
      "Kelime: circuit, Benzerlik Skoru: 0.8184774518013\n",
      "Kelime: failur, Benzerlik Skoru: 0.8037744760513306\n",
      "Kelime: system, Benzerlik Skoru: 0.7873104810714722\n"
     ]
    }
   ],
   "source": [
    "# 16 model için benzer kelimeleri yazdır\n",
    "print_similar_words(model_1, \"Lemmatized CBOW Window 2 Dim 100\")\n",
    "print_similar_words(model_2, \"Stemmed Skipgram Window 4 Dim 100\")\n",
    "print_similar_words(model_3, \"Lemmatized Skipgram Window 2 Dim 300\")\n",
    "print_similar_words(model_4, \"lemmatized skipgram window 4 dim 100\")\n",
    "print_similar_words(model_5, \"lemmatized cbow window 2 dim 300\")\n",
    "print_similar_words(model_6, \"lemmatizedskipgramwindow 2 dim300\")\n",
    "print_similar_words(model_7, \"lemmatized_cbow_window 4_dim300\")\n",
    "print_similar_words(model_8, \"lemmatized_skipgram_window4_dim300.model\")\n",
    "print_similar_words(model_9, \"stemmed_cbow_window2_dim100\")\n",
    "print_similar_words(model_10, \"stemmed_skipgram_window2_dim100\")\n",
    "print_similar_words(model_11, \"stemmed_cbow_window4_dim100\")\n",
    "print_similar_words(model_12, \"stemmed_skipgram_window4_dim100\")\n",
    "print_similar_words(model_13, \"stemmed_cbow_window2_dim300\")\n",
    "print_similar_words(model_14, \"stemmed_skipgram_window2_dim300\")\n",
    "print_similar_words(model_15, \"stemmed_cbow_window4_dim300\")\n",
    "print_similar_words(model_16, \"stemmed_skipgram_window4_dim300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33f2fb9a-f47b-45b2-b6aa-979ee838d5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En sık kullanılan 20 kelime: [('repair', 47), ('check', 46), ('circuit', 41), ('error', 37), ('sensor', 37), ('low', 37), ('perform', 31), ('high', 30), ('fuel', 29), ('oil', 23), ('unit', 23), ('failure', 21), ('control', 21), ('necessary', 21), ('air', 18), ('malfunction', 18), ('pressure', 17), ('load', 17), ('temperature', 16), ('operating', 16)]\n"
     ]
    }
   ],
   "source": [
    "# Veri setinizde en sık geçen 20 kelime\n",
    "from collections import Counter\n",
    "all_words = [word for sentence in tokenized_corpus_lemmatized for word in sentence]\n",
    "print(\"En sık kullanılan 20 kelime:\", Counter(all_words).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f2357-a380-40cb-96e8-4cfbcf767bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
